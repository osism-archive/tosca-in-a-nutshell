.. _logstash_section:

********
Logstash
********

.. contents::
    :local:
    :depth: 3

Logstash is a tool for receiving, processing and outputting logs. All kinds of logs are concerned: system logs, webserver logs, error logs, application logs, etc...
Logstash provides a powerful pipeline for storing, querying, and analyzing logs. It includes an arsenal of built-in inputs, filters, codecs, and outputs, that are integrated as plugins.
See https://www.elastic.co/guide/en/logstash/5.1/index.html for details about all these plugins' configuration.

The Ystia **Logstash** component is packed together with two other components that can be useful for Big Data applications development:

- **GeoNames** component that provides geolocation for Big Data applications
- **Twitter** connector that allows to connect Twitter to Logstash, and thus, to an ELK chain

Logstash Component
------------------
A Logstash node should be hosted on a Java node, which is hosted itself on a compute node as shown in the following figure.
The minimum version of Java is **JRE 8**.

.. image:: docs/images/logstash.png
    :scale: 80
    :align: center

Properties
^^^^^^^^^^

- **component_version:** Version of the component.

- **repository** : Download repository for this component artifacts. Providing a different value allows to specify an alternative repository.
  It is your responsibility to provide an accessible download url and to store required artifacts on it. You should specify only the base
  repository url. Artifacts names will be appended to it, so this property could be shared among several components using the inputs
  feature.

  - Default : https://www.elastic.co/downloads/logstash

- **auto_reload:**  If set to true, Logstash monitors configuration changes and reloads configuration whenever it is changed.

  - Default: false

- **reload_interval:**  If auto-reload is true, this property specifies how frequently to poll the configuration location for changes, in seconds.

- **stdout**:  If set to true, the simple stdout output is added to the output configuration of Logstash.

  - Default: false

- **heap_size**: Sets the heap memory that will be allocated to Logstash java process. It will allocate the same value to both min and max values.

  - Default: 1G

- **log_level:**  Defines Logstash log level. All logs are redirected to a file except if stdout is set to true.

  - Default: warn (very few logs are generated by Logstash).


Requirements
^^^^^^^^^^^^

- **host**: Logstash should be hosted on a Java component. Java 8 or greater is required.
- **consul**: Logstash component requires to be connected to a local Consul Agent. This is required to perform cluster
  discovery.
- **search_endpoint**: allows to connect a Logstash component to Elasticsearch
- **kafka_output**: allows to connect Logstash as the output of a Kafka broker
- **kafka_input**: allows to connect Logstash as the input of a Kafka broker


Capabilities
^^^^^^^^^^^^

- **logstash_resource**: Endpoint used by components that need to connect to Logstash
- **connector_host**: Logstash can host connectors, like for example a Twitter connector

Artifacts
^^^^^^^^^

Input, output and filter configurations can be provided by these dedicated artifacts:

- **input_conf**
- **output_conf**
- **filter_conf**

Artifacts for security configuration:

- **certificates**: Directory containing certificates
- **private_key**: SSL key for logstash forwarder configuration
- **certificate**: SSL certificate for logstash forwarder configuration

Other artifacts:

- **scripts**: Logstash required scripts.
- **config**: Logstash configuration files' directory
- **consul_scripts**: Scripts required by the Consul component.
- **utils_scripts**: Common util scripts for whole Ystia components.

Advanced Functionalities
------------------------

Logstash Relationships
^^^^^^^^^^^^^^^^^^^^^^

Logstash can be used in a simple Elastic Stack toolchain as shown in the following figure.

.. image:: docs/images/logstashSimpleELK.png
   :name: logstash_simple_elk_figure
   :scale: 100
   :align: center

In a more complex toolchain, a **broker** can be used to split the Logstash pipe in two parts: a **shipper** and an **indexer** as shown in the following figure.
.. image:: docs/images/logstashComplexELK.png
   :name: logstash_complex_elk_figure
   :scale: 100
   :align: center

When using Logstash in an Elastic Stack toolchain, it must be related to a Consul agent hosted on its Compute node as shown in the following figure.
This is required for the discovery of the Elasticserach cluster.

.. image:: docs/images/logstashConsul.png
   :name: logstash_consul_figure
   :scale: 100
   :align: center

Dynamic Reconfiguration
^^^^^^^^^^^^^^^^^^^^^^^

You can change the Logstash configuration at runtime without having to redeploy the application.

Three custom commands are available to change the configuration:

- for input configuration files
- for output configuration files
- for filter configuration files

These commands need an argument: the URL of the file to be replaced. No matter how the file name is, it will be renamed to overwrite the previous file.

In the runtime view, select the Logstash component and choose the appropriate custom command.

When the command is started, a green popup appears. Wait a minute for Logstash to be restarted, because the command will stop the process, then restart it.

You can follow the process in the **events** tab.


****

**Limitations**
  If you have a cluster of Logstash, the reconfiguration is valid for all the Logstash instances of the cluster.
  However, in the case of scale up operation, the modifications will not be taken in account.

****

Logstash Elasticity
^^^^^^^^^^^^^^^^^^^^

The component **Logstash Indexer** is scalable.
The scalability of this component allows Log Analysis applications to deal with a huge amount of logs incoming from the Kafka broker.
It is possible to deploy initially a topology with one or more Logstash Indexer and it is possible to
scale out (add) or scale in (remove) Logstash Indexer instances at runtime.

Each Logstash Indexer instance is a consumer of the same Kafka topic but of a different partition of this topic.
If there are more partitions of the Kafka topic than Logstash Indexer (consumer), some consumers will read several partitions.
But if there are more consumers than partitions, some consumers will not be used.
So, it is important to correlate these two values (the number of partitions of the Kafka topic and the number of maximum instances of Logstash Indexer).


Data Management
^^^^^^^^^^^^^^^

If the Elasticsearch component is connected to a Logstash component, you probably want to keep the logs for a certain time.
When it is no longer relevant, you can remove them from the visualization (close the indexes) or even completely erase them.

These features are provided by the following Elasticsearch properties:

- **nb_close_older_than** and **unit_close_older_than** to close old indexes.
- **nb_delete_older_than** and **unit_delete_older_than** to delete old indexes.

For example, to close the indexes older than two months and delete those older than one year, set the parameters as follows:

- nb_close_older_than:   2

- unit_close_older_than:   months

- nb_delete_older_than:   1

- unit_delete_older_than:   years

.. note:: If you leave the parameters unset, data will stand forever.

The close and delete operations are performed by the **Curator** tool in a cron job. By default, the job is started at 02:00 every day.
To override all the parameters, you can change the Cron table file by providing it as an artifact named **curator_cron_tab**.
You can also provide the artifact **curator_action_file** and the **curator_config_file** that will be used to configure the curator.
Below is an example of this file for Centos Linux distribution::

  0 2 * * *    LC_ALL=en_US.utf8 /usr/bin/curator --config /home/curator/curator.yml /home/curator/curator-action

.. note::    The PATH must be absolute and the % must be escaped with a \\ character.

For details on Curator, refer to https://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.html

GeoNames Component
------------------
The **GeoNames** component allows for loading geographical names from the **Geonames** database - http://www.geonames.org, into Elasticsearch.

.. image:: docs/images/geonames.png
    :scale: 80
    :align: center

Download the archive containing geolocation data necessary for your application from http://download.geonames.org/export/zip,
and install it into a local repository accessible to your application's hosts.

Properties
^^^^^^^^^^

- **repository** : Address of the local repository containing the geolocation data archive.

  - Required
  - Default: ""

- **filename** : Name of the geolocation data archive.

  - Required
  - Default: "allCountries".


- **indexname** : Name of the target Elasticsearch index.

  - Required
  - Default: "starlings_geonames"


Requirements
^^^^^^^^^^^^

- **host**: GeoNames should be hosted on a Logstash node

Capabilities
^^^^^^^^^^^^

- **geonames_resource**: Endpoint used by components that need to connect to GeoNames

Artifacts
^^^^^^^^^

- **geoscripts**: GeoNames required scripts.


Twitter Connector
-----------------
The **Twitter Connector** component allows you to connect Twitter to the ELK chain via Logstash, in order to get tweets, filtering them by keywords, language, etc...
The following figure shows a Twitter node configuration.

.. image:: docs/images/twitter-connector.png
   :name: Twitter_figure
   :scale: 100
   :align: center

Properties
^^^^^^^^^^

- **consumer_key** : Your Twitter App’s consumer key.

  - Required
  - Default: ""

- **consumer_secret** : Your Twitter App’s consumer secret.

  - Required
  - Default: ""

- **oauth_token** : Your Twitter oauth token.

  - Required
  - Default: ""

- **oauth_token_secret** : Your Twitter oauth token secret.

  - Required
  - Default: ""

- **use_proxy** : Use a proxy to handle the connections.

  - Default: "false"

- **proxy_address** : Address of the proxy to use. If use_proxy property is true, and no value is set for this property,
  then default environment proxy settings on the compute will be used.

  - Default: ""

- **proxy_port** : Port of the proxy to use. If use_proxy property is true, and no value is set for this property,
  then default environment proxy settings on the compute will be used.

  - Default: ""

- **keywords** : An array of keywords to track in the Twitter stream. Example: ["foo", "bar"].

  - Default: ""

- **follows** : An array of user IDs, indicating the users to return statuses for in the Twitter stream. Example: ["ID1", "ID2"].

  - Default: ""

- **languages** : An array of BCP 47 language identifiers corresponding to any of the languages listed on Twitter’s advanced search page
  will only return tweets that have been detected as being written in the specified languages. Example: [ "en", "fr" ].

  - Default: ""

- **use_samples** : Returns a small random sample of all public statuses.
  If set to true, the **keywords**, **follows** and **languages** properties will be ignored.

  - Default: "false"

- **full_tweet** : Record full tweet object as given by the Twitter Streaming API.

  - Default: "false"

- **ignore_retweets** : Ignore the retweets coming out of the Twitter API.

  - Default: "false"

- **tags** : An array of tags to add to your event. This can help with processing later. Example: ["tagName"].

  - Default: ""

****

**Note**
  At least one of **keywords** or **follows** property must be specified if the **use_samples** property is not set.

****

Twitter Connector Dynamic Reconfiguration
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

You can change the Twitter Connector configuration at runtime without having to redeploy the application.

The following commands are available to change the configuration:

- **change_authentication**: To change the Twitter account to get tweets.

  - *consumer_key*
  - *consumer_secret*
  - *oauth_token*
  - *oauth_token_secret*

- **change_full_tweet**: To change the *full_tweet* property.

- **change_use_samples**: To change the *use_samples* property.

- **change_ignore_retweets**: To change the *ignore_retweets* property.

- **change_follows**: To change the *follows* property.

- **add_follows**: To add user ID to the *follows* property.

- **remove_follows**: To remove user ID from the *follows* property.

- **change_tags**: To change the *tags* property.

- **add_tags**: To add values to the *tags*  property.

- **remove_tags**: To remove values from the *tags*  property.

- **change_keywords**: To change the *keywords* property.

- **add_keywords**: To add values to the *keywords* property.

- **remove_keywords**: To remove values from the *keywords* property.

- **change_languages**: To change the *languages* property.

- **add_languages**: To add values to the *languages* property.

- **remove_languages**: To remove values from the *languages* property.


****

**Note**
  The value of the **tags**, **keywords** and **languages** properties can be either:

  - An array of string (["word1", "word2"]). In this case, the initial value (used at deployment time) will be replaced.
  - Or empty. In this case, the property will be removed from the configuration of the Twitter Connector.

  The **follows** property requires an array of Twitter accounts (["@id1", "@id2", "@id3"]).

****
